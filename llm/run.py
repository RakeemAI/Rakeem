import os
import sys
import pandas as pd
from dotenv import load_dotenv

# ØªØ­Ù…ÙŠÙ„ .env ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
load_dotenv(override=True)

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø§Øª
from step1_prompt_engineer import ArabicPromptEngineer
from step2_chain_setup import LangChainSetup
from step3_context_formatter import ContextFormatter
from step4_response_parser import ResponseParser

class RakeemChatbot:
    """Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø´Ø§Øª Ø¨ÙˆØª"""
    
    def __init__(self, excel_file_path=None):
        print("ğŸ¤– Ø¬Ø§Ø±ÙŠ ØªÙ‡ÙŠØ¦Ø© Ø´Ø§Øª Ø¨ÙˆØª Ø±ÙƒÙŠÙ…...")
        
        # 1. ØªÙ‡ÙŠØ¦Ø© Prompt Engineer
        self.prompt_engineer = ArabicPromptEngineer()
        print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Prompt Engineer")
        
        # 2. ØªÙ‡ÙŠØ¦Ø© LangChain + RAG
        self.chain_setup = LangChainSetup()
        self.chain_setup.setup_llm()
        self.chain_setup.setup_memory()
        self.chain_setup.setup_retriever()
        print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ LangChain + RAG")
        
        # 3. ØªÙ‡ÙŠØ¦Ø© Context Formatter
        self.context_formatter = ContextFormatter()
        
        # 4. ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ù† Excel
        self.company_data = None
        if excel_file_path and os.path.exists(excel_file_path):
            try:
                self.company_data = pd.read_excel(excel_file_path)
                print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ©: {len(self.company_data)} ØµÙ")
            except Exception as e:
                print(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Excel: {e}")
        else:
            print("âš ï¸ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ù„Ù Excel")
        
        # 5. ØªÙ‡ÙŠØ¦Ø© Response Parser
        self.response_parser = ResponseParser()
        print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Response Parser")
        
        print(f"\nğŸ‰ Ø´Ø§Øª Ø¨ÙˆØª Ø±ÙƒÙŠÙ… Ø¬Ø§Ù‡Ø²! Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {self.chain_setup.model_name}")
    
    def ask_question(self, question: str) -> dict:
        """Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ø´Ø§Øª Ø¨ÙˆØª"""
        try:
            # Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
            query_type = self.prompt_engineer.detect_query_type(question)
            print(f"ğŸ” Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„: {query_type}")
            
            # Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø³ÙŠØ§Ù‚Ø§Øª Ø§Ù„Ø£Ø±Ø¨Ø¹Ø©
            company_info = ""
            financial_data = ""
            zatca_info = ""
            
            # Ø¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ© ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©
            if self.company_data is not None and not self.company_data.empty:
                company_info = self.context_formatter.format_company_info(self.company_data)
                financial_data = self.context_formatter.format_financial_context(self.company_data)
            
            # Ø¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ZATCA Ù…Ù† RAG (Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø£Ùˆ ØªÙ†Ø¸ÙŠÙ…ÙŠ)
            if query_type in ['legal', 'zatca', 'compliance']:
                rag_context = self.chain_setup.get_context_from_rag(question)
                if rag_context:
                    zatca_info = rag_context
            
            # Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù€ prompt Ø¨Ø§Ù„Ù€ 4 parameters
            formatted_prompt = self.prompt_engineer.format_main_prompt(
                company_info=company_info,
                financial_data=financial_data,
                zatca_info=zatca_info,
                question=question
            )
            
            # Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ LLM
            llm_response = self.chain_setup.ask_question_real(formatted_prompt, context=None)
            
            # Ø§Ù„Ø®Ø·ÙˆØ© 5: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
            parsed_response = self.response_parser.parse_llm_response(llm_response['answer'])
            
            # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
            return {
                "answer": llm_response['answer'],
                "parsed": parsed_response,
                "query_type": query_type,
                "used_rag": llm_response.get('used_rag', False),
                "source_documents": llm_response.get('source_documents', [])
            }
            
        except Exception as e:
            error_msg = f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return {
                "answer": error_msg,
                "parsed": {"content": error_msg, "confidence": 0},
                "query_type": "error",
                "used_rag": False
            }
    
    def clear_memory(self):
        """Ù…Ø³Ø­ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        self.chain_setup.clear_memory()
        print("âœ… ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©")

# Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
if __name__ == "__main__":
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Rakeem Chatbot")
    print("=" * 60)
    
    chatbot = RakeemChatbot(excel_file_path='./Rakeem/data/operation_data_Rakeem.xlsx')
    
    question = "Ù…Ø§ Ù‡ÙŠ Ø´Ø±ÙˆØ· Ø¥ØµØ¯Ø§Ø± Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŸ"
    print(f"\nğŸ“ Ø§Ù„Ø³Ø¤Ø§Ù„: {question}")
    
    response = chatbot.ask_question(question)
    print(f"\nğŸ’¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\n{response['answer']}")
