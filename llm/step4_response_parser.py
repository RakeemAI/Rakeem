import re
import json
from typing import Dict, List, Any

class ResponseParser:
    """Step 4: ØªØ­Ù„ÙŠÙ„ ÙˆØªÙ†Ø¸ÙŠÙ… Ø±Ø¯ÙˆØ¯ Ø§Ù„Ù€ LLM"""
    
    def __init__(self):
        self.sources = []
        self.financial_numbers = {}
        
    def parse_llm_response(self, response: Any) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø±Ø¯ Ø§Ù„Ù€ LLM ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
        try:
            parsed_response = {
                "answer": "",
                "sources": [],
                "financial_advice": [],
                "warnings": [],
                "citations": [],
                "numbers": {}
            }
            
            if isinstance(response, str):
                parsed_response["answer"] = response
                parsed_response.update(self._extract_components_from_text(response))
            elif isinstance(response, dict):
                parsed_response = self._parse_structured_response(response)
            else:
                parsed_response["answer"] = str(response)
                
            return parsed_response
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¯: {e}")
            return {
                "answer": str(response),
                "sources": [],
                "financial_advice": [],
                "warnings": [],
                "citations": [],
                "numbers": {}
            }
    
    def _parse_structured_response(self, response_dict: Dict) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ù‡ÙŠÙƒÙ„ Ù…Ù† LangChain"""
        parsed = {
            "answer": response_dict.get('answer', ''),
            "sources": [],
            "financial_advice": [],
            "warnings": [],
            "citations": [],
            "numbers": {}
        }
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
        source_docs = response_dict.get('source_documents', [])
        for doc in source_docs:
            source_info = {
                "content": doc.page_content[:200] + "..." if hasattr(doc, 'page_content') and len(doc.page_content) > 200 else getattr(doc, 'page_content', ''),
                "source": doc.metadata.get('source', 'Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ') if hasattr(doc, 'metadata') else 'Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'
            }
            parsed["sources"].append(source_info)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©
        if parsed["answer"]:
            text_analysis = self._extract_components_from_text(parsed["answer"])
            parsed.update(text_analysis)
            
        return parsed
    
    def _extract_components_from_text(self, text: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
        components = {
            "financial_advice": self._extract_financial_advice(text),
            "warnings": self._extract_warnings(text),
            "citations": self._extract_citations(text),
            "numbers": self._extract_financial_numbers(text)
        }
        return components
    
    def _extract_financial_advice(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
        advice_patterns = [
            r'Ù†ØµÙŠØ­Ø©[^:]*:[^\n]*',
            r'ØªÙˆØµÙŠØ©[^:]*:[^\n]*', 
            r'ÙŠÙ†ØµØ­[^\n]*',
            r'ÙŠÙÙØ¶Ù„[^\n]*',
            r'ÙŠÙ…ÙƒÙ†Ùƒ[^\n]*',
            r'Ù†Ù†ØµØ­[^\n]*'
        ]
        
        advice_list = []
        for pattern in advice_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.UNICODE)
            advice_list.extend(matches)
            
        return advice_list[:3]  # Ø£ÙˆÙ„ 3 Ù†ØµØ§Ø¦Ø­ ÙÙ‚Ø·
    
    def _extract_warnings(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ù…Ù† Ø§Ù„Ù†Øµ"""
        warning_patterns = [
            r'ØªØ­Ø°ÙŠØ±[^:]*:[^\n]*',
            r'âš ï¸[^\n]*',
            r'Ø§Ù†ØªØ¨Ù‡[^\n]*',
            r'Ø§Ø­Ø°Ø±[^\n]*',
            r'Ø®Ø·Ø±[^\n]*',
            r'ØªÙ†Ø¨ÙŠÙ‡[^\n]*'
        ]
        
        warnings = []
        for pattern in warning_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.UNICODE)
            warnings.extend(matches)
            
        return warnings
    
    def _extract_citations(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø± Ù…Ù† Ø§Ù„Ù†Øµ"""
        citation_patterns = [
            r'Ø§Ù„Ù…ØµØ¯Ø±[^:]*:[^\n]*',
            r'Ø§Ù„Ù…Ø±Ø¬Ø¹[^:]*:[^\n]*',
            r'Ø­Ø³Ø¨[^\n]*ZATCA[^\n]*',
            r'ÙˆÙÙ‚Ø§Ù‹[^\n]*ZATCA[^\n]*',
            r'Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰[^\n]*ZATCA[^\n]*'
        ]
        
        citations = []
        for pattern in citation_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.UNICODE)
            citations.extend(matches)
            
        return citations
    
    def _extract_financial_numbers(self, text: str) -> Dict[str, float]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
        # Ø£Ù†Ù…Ø§Ø· Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§Ù„ÙŠØ©
        number_patterns = {
            "Ø¥ÙŠØ±Ø§Ø¯Ø§Øª": r'(Ø¥ÙŠØ±Ø§Ø¯Ø§Øª?|revenue)[^\d]*([\d,]+(?:\.\d+)?)',
            "Ù…ØµØ±ÙˆÙØ§Øª": r'(Ù…ØµØ±ÙˆÙØ§Øª?|expenses)[^\d]*([\d,]+(?:\.\d+)?)',
            "Ø±Ø¨Ø­": r'(Ø±Ø¨Ø­|profit)[^\d]*([\d,]+(?:\.\d+)?)',
            "Ø¶Ø±ÙŠØ¨Ø©": r'(Ø¶Ø±ÙŠØ¨Ø©|vat)[^\d]*([\d,]+(?:\.\d+)?)',
            "Ø²ÙƒØ§Ø©": r'(Ø²ÙƒØ§Ø©|zakat)[^\d]*([\d,]+(?:\.\d+)?)',
            "Ù†Ø³Ø¨Ø©": r'([\d,]+(?:\.\d+)?)%'
        }
        
        numbers = {}
        for key, pattern in number_patterns.items():
            matches = re.findall(pattern, text, re.IGNORECASE | re.UNICODE)
            if matches:
                # Ø£Ø®Ø° Ø¢Ø®Ø± Ø±Ù‚Ù… ÙˆØ¬Ø¯ (ØºØ§Ù„Ø¨Ø§Ù‹ Ø§Ù„Ø£ÙƒØ«Ø± ØµÙ„Ø©)
                last_match = matches[-1]
                try:
                    if key == "Ù†Ø³Ø¨Ø©":
                        number_str = last_match[0].replace(',', '')
                    else:
                        number_str = last_match[1].replace(',', '')
                    numbers[key] = float(number_str)
                except (ValueError, IndexError):
                    continue
                    
        return numbers
    
    def format_final_response(self, parsed_response: Dict[str, Any]) -> str:
        """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        try:
            final_text = ""
            
            # Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            if parsed_response.get("answer"):
                final_text += f"{parsed_response['answer']}\n\n"
            
            # Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ù…Ø§Ù„ÙŠØ©
            if parsed_response.get("financial_advice"):
                final_text += "ğŸ’¡ **Ø§Ù„Ù†ØµØ§Ø¦Ø­ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª:**\n"
                for advice in parsed_response["financial_advice"]:
                    final_text += f"â€¢ {advice}\n"
                final_text += "\n"
            
            # Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª
            if parsed_response.get("warnings"):
                final_text += "âš ï¸ **Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ù‡Ø§Ù…Ø©:**\n"
                for warning in parsed_response["warnings"]:
                    final_text += f"â€¢ {warning}\n"
                final_text += "\n"
            
            # Ø§Ù„Ù…ØµØ§Ø¯Ø±
            if parsed_response.get("sources"):
                final_text += "ğŸ“š **Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:**\n"
                for i, source in enumerate(parsed_response["sources"][:2], 1):
                    final_text += f"{i}. {source.get('source', 'Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}\n"
            
            return final_text
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {e}")
            return parsed_response.get("answer", "âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯")

# Ø§Ø®ØªØ¨Ø§Ø± Step 4
if __name__ == "__main__":
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Step 4 - Response Parser")
    print("=" * 40)
    
    parser = ResponseParser()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ø±Ø¯ ØªØ¬Ø±ÙŠØ¨ÙŠ
    test_response = {
        "answer": "Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§ØªÙƒØŒ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª 100,000 Ø±ÙŠØ§Ù„ ÙˆØ§Ù„Ù…ØµØ±ÙˆÙØ§Øª 80,000 Ø±ÙŠØ§Ù„. Ù†ØµÙŠØ­Ø©: ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…ØµØ±ÙˆÙØ§Øª Ø¨Ù†Ø³Ø¨Ø© 10%. ØªØ­Ø°ÙŠØ±: Ø§Ù†ØªØ¨Ù‡ Ù„Ù„ØªØ¯ÙÙ‚ Ø§Ù„Ù†Ù‚Ø¯ÙŠ. Ø§Ù„Ù…ØµØ¯Ø±: Ø¯Ù„ÙŠÙ„ ZATCA Ù„Ù„Ø¶Ø±Ø§Ø¦Ø¨",
        "source_documents": [
            type('MockDoc', (), {
                'page_content': 'Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø¶Ø±Ø§Ø¦Ø¨ ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©...',
                'metadata': {'source': 'https://zatca.gov.sa/documents/tax-guide.pdf'}
            })()
        ]
    }
    
    print("1. Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¯...")
    parsed = parser.parse_llm_response(test_response)
    print(f"   âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¯")
    print(f"   ğŸ“Š Ø§Ù„Ù†ØµØ§Ø¦Ø­: {len(parsed['financial_advice'])}")
    print(f"   âš ï¸ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª: {len(parsed['warnings'])}")
    print(f"   ğŸ”¢ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…: {parsed['numbers']}")
    
    print("2. Ø§Ø®ØªØ¨Ø§Ø± ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ...")
    final_response = parser.format_final_response(parsed)
    print(f"   âœ… Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {len(final_response)} Ø­Ø±Ù")
    print(f"   ğŸ“ Ø¹ÙŠÙ†Ø©: {final_response[:100]}...")
    
    print("\nâœ… Step 4 Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¹Ù…Ù„!")
